#!/usr/bin/env python3
"""
æµ‹è¯• Google Scholar å¼•ç”¨çˆ¬è™«
ç”¨æ³•ç¤ºä¾‹å’Œç®€å•æµ‹è¯•
"""

from papertracer import GoogleScholarCrawler, print_citation_tree, save_tree_to_json
import sys

def test_crawler_basic():
    """åŸºæœ¬åŠŸèƒ½æµ‹è¯•"""
    print("ğŸ§ª å¼€å§‹åŸºæœ¬åŠŸèƒ½æµ‹è¯•...")
    
    # ä½¿ç”¨è¾ƒå°çš„å‚æ•°è¿›è¡Œæµ‹è¯•
    crawler = GoogleScholarCrawler(
        max_depth=2,  # è¾ƒå°çš„æ·±åº¦
        max_papers_per_level=3,  # è¾ƒå°‘çš„è®ºæ–‡æ•°
        delay_range=(0.5, 1.5)  # è¾ƒçŸ­çš„å»¶è¿Ÿ
    )
    
    # æµ‹è¯•URL
    test_url = "https://scholar.google.com/scholar?cites=11002616430871081935&as_sdt=2005&sciodt=0,5&hl=en"
    
    print(f"ğŸ“‹ æµ‹è¯•URL: {test_url}")
    print(f"ğŸ”§ é…ç½®: æ·±åº¦={crawler.max_depth}, æ¯å±‚è®ºæ–‡æ•°={crawler.max_papers_per_level}")
    print("-" * 60)
    
    try:
        # æ„å»ºå¼•ç”¨æ ‘
        citation_tree = crawler.build_citation_tree(test_url)
        
        if citation_tree:
            print("\nâœ… æµ‹è¯•æˆåŠŸï¼å¼•ç”¨æ ‘æ„å»ºå®Œæˆ")
            print("=" * 60)
            
            # æ‰“å°æ ‘ç»“æ„
            print_citation_tree(citation_tree)
            
            # ä¿å­˜ç»“æœ
            save_tree_to_json(citation_tree, "test_citation_tree.json")
            
            # ç»Ÿè®¡ä¿¡æ¯
            def count_nodes(node):
                count = 1
                for child in node.children:
                    count += count_nodes(child)
                return count
            
            total_papers = count_nodes(citation_tree)
            print(f"\nğŸ“Š æµ‹è¯•ç»“æœç»Ÿè®¡:")
            print(f"   âœ“ æ€»è®ºæ–‡æ•°: {total_papers}")
            print(f"   âœ“ æ ‘çš„æœ€å¤§æ·±åº¦: {crawler.max_depth}")
            print(f"   âœ“ æ ¹èŠ‚ç‚¹ç›´æ¥å­èŠ‚ç‚¹: {len(citation_tree.children)}")
            print(f"   âœ“ ç»“æœå·²ä¿å­˜åˆ°: test_citation_tree.json")
            
            return True
            
        else:
            print("âŒ æµ‹è¯•å¤±è´¥ï¼šæ— æ³•æ„å»ºå¼•ç”¨æ ‘")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return False

def interactive_test():
    """äº¤äº’å¼æµ‹è¯•"""
    print("\nğŸ¯ äº¤äº’å¼æµ‹è¯•æ¨¡å¼")
    print("è¯·è¾“å…¥è¦çˆ¬å–çš„Google Scholaré“¾æ¥ï¼ˆç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤é“¾æ¥ï¼‰:")
    
    url = input().strip()
    if not url:
        url = "https://scholar.google.com/scholar?cites=11002616430871081935&as_sdt=2005&sciodt=0,5&hl=en"
        print(f"ä½¿ç”¨é»˜è®¤é“¾æ¥: {url}")
    
    print("\nè¯·é…ç½®çˆ¬è™«å‚æ•°ï¼ˆç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤å€¼ï¼‰:")
    
    # è·å–æ·±åº¦
    depth_input = input("æœ€å¤§é€’å½’æ·±åº¦ (é»˜è®¤2): ").strip()
    max_depth = int(depth_input) if depth_input.isdigit() else 2
    
    # è·å–æ¯å±‚è®ºæ–‡æ•°
    papers_input = input("æ¯å±‚æœ€å¤šè®ºæ–‡æ•° (é»˜è®¤5): ").strip()
    max_papers = int(papers_input) if papers_input.isdigit() else 5
    
    # è·å–å»¶è¿Ÿæ—¶é—´
    delay_input = input("è¯·æ±‚é—´éš”ç§’æ•° (é»˜è®¤1-2): ").strip()
    delay = float(delay_input) if delay_input.replace('.', '').isdigit() else 1.5
    
    print(f"\nğŸ”§ é…ç½®ç¡®è®¤:")
    print(f"   URL: {url}")
    print(f"   æœ€å¤§æ·±åº¦: {max_depth}")
    print(f"   æ¯å±‚è®ºæ–‡æ•°: {max_papers}")
    print(f"   è¯·æ±‚é—´éš”: {delay}ç§’")
    print(f"   é¢„ä¼°è¿è¡Œæ—¶é—´: {delay * max_papers * (max_papers ** max_depth) / 60:.1f} åˆ†é’Ÿ")
    
    confirm = input("\nç¡®è®¤å¼€å§‹çˆ¬å–ï¼Ÿ(y/N): ").strip().lower()
    if confirm != 'y':
        print("âŒ å–æ¶ˆæ“ä½œ")
        return
    
    # åˆ›å»ºçˆ¬è™«å®ä¾‹
    crawler = GoogleScholarCrawler(
        max_depth=max_depth,
        max_papers_per_level=max_papers,
        delay_range=(delay, delay + 0.5)
    )
    
    try:
        print("\nğŸš€ å¼€å§‹çˆ¬å–...")
        citation_tree = crawler.build_citation_tree(url)
        
        if citation_tree:
            print("\nâœ… çˆ¬å–å®Œæˆï¼")
            print("=" * 60)
            
            # æ˜¾ç¤ºç»“æœ
            print_citation_tree(citation_tree)
            
            # ä¿å­˜ç»“æœ
            filename = f"citation_tree_{int(time.time())}.json"
            save_tree_to_json(citation_tree, filename)
            
            print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {filename}")
            
        else:
            print("âŒ çˆ¬å–å¤±è´¥")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"âŒ çˆ¬å–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ•·ï¸  Google Scholar å¼•ç”¨çˆ¬è™«æµ‹è¯•å·¥å…·")
    print("=" * 60)
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "--test":
            # è¿è¡ŒåŸºæœ¬æµ‹è¯•
            success = test_crawler_basic()
            sys.exit(0 if success else 1)
        elif sys.argv[1] == "--interactive":
            # è¿è¡Œäº¤äº’å¼æµ‹è¯•
            interactive_test()
            return
    
    # é»˜è®¤æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
    print("ä½¿ç”¨æ–¹æ³•:")
    print("  python test_crawler.py --test        # è¿è¡ŒåŸºæœ¬åŠŸèƒ½æµ‹è¯•")
    print("  python test_crawler.py --interactive # äº¤äº’å¼é…ç½®å’Œæµ‹è¯•")
    print("  python test_crawler.py               # æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯")
    print()
    print("æ³¨æ„äº‹é¡¹:")
    print("  1. è¯·éµå®ˆGoogle Scholarçš„ä½¿ç”¨æ¡æ¬¾")
    print("  2. é¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚ï¼Œå»ºè®®è®¾ç½®åˆé€‚çš„å»¶è¿Ÿæ—¶é—´")
    print("  3. å¤§è§„æ¨¡çˆ¬å–å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…")
    print("  4. å¦‚æœé‡åˆ°åçˆ¬æªæ–½ï¼Œå¯ä»¥å°è¯•å¢åŠ å»¶è¿Ÿæ—¶é—´")

if __name__ == "__main__":
    import time
    main()
