#!/usr/bin/env python3
"""
PaperTracer æ€§èƒ½ç›‘æ§å·¥å…·
å®æ—¶ç›‘æ§çˆ¬è™«æ€§èƒ½ï¼Œæ£€æµ‹å¼‚å¸¸æƒ…å†µå¹¶æä¾›ä¼˜åŒ–å»ºè®®
"""

import sys
import os
import json
import time
import psutil
from pathlib import Path
from datetime import datetime, timedelta
from dataclasses import dataclass
from typing import List, Dict, Optional
from papertracer_config import Config
from logger import get_logger

@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡æ•°æ®ç±»"""
    timestamp: datetime
    requests_per_minute: float
    average_delay: float
    error_rate: float
    memory_usage_mb: float
    cpu_usage_percent: float
    network_latency_ms: float
    consecutive_429_count: int
    success_rate: float

class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self, session_dir: str = None):
        self.logger = get_logger()
        self.session_dir = Path(session_dir) if session_dir else None
        self.metrics_history: List[PerformanceMetrics] = []
        self.start_time = datetime.now()
        self.last_request_count = 0
        self.last_check_time = datetime.now()
        
    def collect_system_metrics(self) -> Dict:
        """æ”¶é›†ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡"""
        process = psutil.Process()
        
        return {
            'memory_usage_mb': process.memory_info().rss / (1024 * 1024),
            'cpu_usage_percent': process.cpu_percent(),
            'system_memory_percent': psutil.virtual_memory().percent,
            'system_cpu_percent': psutil.cpu_percent(),
            'network_connections': len(process.connections()),
            'open_files': len(process.open_files())
        }
    
    def collect_crawler_metrics(self, crawler) -> Dict:
        """æ”¶é›†çˆ¬è™«æ€§èƒ½æŒ‡æ ‡"""
        current_time = datetime.now()
        time_diff = (current_time - self.last_check_time).total_seconds()
        
        # è®¡ç®—è¯·æ±‚é€Ÿç‡
        request_diff = crawler.request_count - self.last_request_count
        requests_per_minute = (request_diff / time_diff) * 60 if time_diff > 0 else 0
        
        # æ›´æ–°è®°å½•
        self.last_request_count = crawler.request_count
        self.last_check_time = current_time
        
        # è®¡ç®—æˆåŠŸç‡
        total_attempts = crawler.request_count
        success_rate = 1.0 - (crawler.consecutive_429_count / max(total_attempts, 1))
        
        return {
            'total_requests': crawler.request_count,
            'requests_per_minute': requests_per_minute,
            'visited_urls': len(crawler.visited_urls),
            'consecutive_429_count': getattr(crawler, 'consecutive_429_count', 0),
            'success_rate': success_rate,
            'last_429_time': getattr(crawler, 'last_429_time', None),
            'session_duration_minutes': (current_time - self.start_time).total_seconds() / 60
        }
    
    def measure_network_latency(self) -> float:
        """æµ‹é‡ç½‘ç»œå»¶è¿Ÿ"""
        import requests
        try:
            start_time = time.time()
            response = requests.head('https://scholar.google.com', timeout=5)
            latency = (time.time() - start_time) * 1000
            return latency
        except:
            return -1  # è¡¨ç¤ºæµ‹é‡å¤±è´¥
    
    def create_performance_snapshot(self, crawler) -> PerformanceMetrics:
        """åˆ›å»ºæ€§èƒ½å¿«ç…§"""
        system_metrics = self.collect_system_metrics()
        crawler_metrics = self.collect_crawler_metrics(crawler)
        network_latency = self.measure_network_latency()
        
        # ä¼°ç®—å¹³å‡å»¶è¿Ÿ
        delay_range = getattr(crawler, 'delay_range', (2, 5))
        estimated_delay = sum(delay_range) / 2
        
        metrics = PerformanceMetrics(
            timestamp=datetime.now(),
            requests_per_minute=crawler_metrics['requests_per_minute'],
            average_delay=estimated_delay,
            error_rate=1.0 - crawler_metrics['success_rate'],
            memory_usage_mb=system_metrics['memory_usage_mb'],
            cpu_usage_percent=system_metrics['cpu_usage_percent'],
            network_latency_ms=network_latency,
            consecutive_429_count=crawler_metrics['consecutive_429_count'],
            success_rate=crawler_metrics['success_rate']
        )
        
        self.metrics_history.append(metrics)
        return metrics
    
    def analyze_performance_trends(self) -> Dict:
        """åˆ†ææ€§èƒ½è¶‹åŠ¿"""
        if len(self.metrics_history) < 2:
            return {'status': 'insufficient_data'}
        
        recent_metrics = self.metrics_history[-5:]  # æœ€è¿‘5ä¸ªæ•°æ®ç‚¹
        old_metrics = self.metrics_history[-10:-5] if len(self.metrics_history) >= 10 else self.metrics_history[:-5]
        
        if not old_metrics:
            return {'status': 'insufficient_historical_data'}
        
        # è®¡ç®—è¶‹åŠ¿
        recent_avg_rpm = sum(m.requests_per_minute for m in recent_metrics) / len(recent_metrics)
        old_avg_rpm = sum(m.requests_per_minute for m in old_metrics) / len(old_metrics)
        
        recent_avg_error = sum(m.error_rate for m in recent_metrics) / len(recent_metrics)
        old_avg_error = sum(m.error_rate for m in old_metrics) / len(old_metrics)
        
        recent_avg_latency = sum(m.network_latency_ms for m in recent_metrics if m.network_latency_ms > 0)
        recent_avg_latency = recent_avg_latency / len([m for m in recent_metrics if m.network_latency_ms > 0]) if recent_avg_latency else 0
        
        return {
            'status': 'analyzed',
            'rpm_trend': 'improving' if recent_avg_rpm > old_avg_rpm else 'declining',
            'rpm_change_percent': ((recent_avg_rpm - old_avg_rpm) / max(old_avg_rpm, 1)) * 100,
            'error_trend': 'improving' if recent_avg_error < old_avg_error else 'worsening',
            'error_change_percent': ((recent_avg_error - old_avg_error) / max(old_avg_error, 0.01)) * 100,
            'average_latency_ms': recent_avg_latency,
            'current_rpm': recent_avg_rpm,
            'current_error_rate': recent_avg_error
        }
    
    def generate_optimization_recommendations(self, trends: Dict, current_metrics: PerformanceMetrics) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        # å†…å­˜ä½¿ç”¨å»ºè®®
        if current_metrics.memory_usage_mb > 500:
            recommendations.append("âš ï¸  å†…å­˜ä½¿ç”¨è¿‡é«˜ (>500MB)ï¼Œè€ƒè™‘é™ä½max_papers_per_levelæˆ–é‡å¯çˆ¬è™«")
        
        # CPUä½¿ç”¨å»ºè®®
        if current_metrics.cpu_usage_percent > 80:
            recommendations.append("âš ï¸  CPUä½¿ç”¨ç‡è¿‡é«˜ï¼Œè€ƒè™‘å¢åŠ å»¶è¿Ÿæ—¶é—´")
        
        # ç½‘ç»œå»¶è¿Ÿå»ºè®®
        if current_metrics.network_latency_ms > 2000:
            recommendations.append("âš ï¸  ç½‘ç»œå»¶è¿Ÿè¿‡é«˜ (>2s)ï¼Œå¯èƒ½éœ€è¦æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ä½¿ç”¨ä»£ç†")
        elif current_metrics.network_latency_ms < 0:
            recommendations.append("âŒ æ— æ³•è¿æ¥åˆ°Google Scholarï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
        
        # 429é”™è¯¯å»ºè®®
        if current_metrics.consecutive_429_count > 3:
            recommendations.append("ğŸš¨ è¿ç»­429é”™è¯¯è¿‡å¤šï¼Œå»ºè®®ï¼š1) å¢åŠ å»¶è¿Ÿ 2) æ›´æ¢User-Agent 3) ä½¿ç”¨ä»£ç†")
        elif current_metrics.consecutive_429_count > 0:
            recommendations.append("âš ï¸  é‡åˆ°429é”™è¯¯ï¼Œç³»ç»Ÿæ­£åœ¨è‡ªåŠ¨è°ƒæ•´å»¶è¿Ÿç­–ç•¥")
        
        # æˆåŠŸç‡å»ºè®®
        if current_metrics.success_rate < 0.8:
            recommendations.append("âš ï¸  æˆåŠŸç‡åä½ (<80%)ï¼Œå»ºè®®æ£€æŸ¥ç½‘ç»œå’Œå»¶è¿Ÿé…ç½®")
        elif current_metrics.success_rate > 0.95:
            recommendations.append("âœ… æˆåŠŸç‡è‰¯å¥½ (>95%)ï¼Œå¯ä»¥è€ƒè™‘é€‚å½“é™ä½å»¶è¿Ÿä»¥æé«˜æ•ˆç‡")
        
        # è¯·æ±‚é€Ÿç‡å»ºè®®
        if trends.get('status') == 'analyzed':
            current_rpm = trends['current_rpm']
            if current_rpm < 1:
                recommendations.append("âš ï¸  è¯·æ±‚é€Ÿç‡è¿‡ä½ (<1/min)ï¼Œè€ƒè™‘é™ä½å»¶è¿Ÿæˆ–æ£€æŸ¥æ˜¯å¦è¢«é˜»æ­¢")
            elif current_rpm > 10:
                recommendations.append("âš ï¸  è¯·æ±‚é€Ÿç‡å¯èƒ½è¿‡é«˜ (>10/min)ï¼Œå»ºè®®å¢åŠ å»¶è¿Ÿä»¥é¿å…è¢«æ£€æµ‹")
        
        # è¶‹åŠ¿å»ºè®®
        if trends.get('rpm_trend') == 'declining' and trends.get('rpm_change_percent', 0) < -20:
            recommendations.append("ğŸ“‰ è¯·æ±‚é€Ÿç‡ä¸‹é™æ˜æ˜¾ï¼Œå¯èƒ½é‡åˆ°äº†åçˆ¬è™«é™åˆ¶")
        
        if trends.get('error_trend') == 'worsening':
            recommendations.append("ğŸ“ˆ é”™è¯¯ç‡ä¸Šå‡ï¼Œå»ºè®®æš‚åœå¹¶è°ƒæ•´ç­–ç•¥")
        
        if not recommendations:
            recommendations.append("âœ… å½“å‰æ€§èƒ½è‰¯å¥½ï¼Œç»§ç»­ä¿æŒ")
        
        return recommendations
    
    def save_performance_report(self, filepath: str):
        """ä¿å­˜æ€§èƒ½æŠ¥å‘Š"""
        if not self.metrics_history:
            self.logger.warning("æ²¡æœ‰æ€§èƒ½æ•°æ®å¯ä¿å­˜")
            return
        
        report = {
            'generated_at': datetime.now().isoformat(),
            'session_duration_minutes': (datetime.now() - self.start_time).total_seconds() / 60,
            'total_metrics_collected': len(self.metrics_history),
            'summary': {
                'avg_requests_per_minute': sum(m.requests_per_minute for m in self.metrics_history) / len(self.metrics_history),
                'avg_success_rate': sum(m.success_rate for m in self.metrics_history) / len(self.metrics_history),
                'max_memory_usage_mb': max(m.memory_usage_mb for m in self.metrics_history),
                'avg_network_latency_ms': sum(m.network_latency_ms for m in self.metrics_history if m.network_latency_ms > 0) / max(len([m for m in self.metrics_history if m.network_latency_ms > 0]), 1),
                'max_consecutive_429_count': max(m.consecutive_429_count for m in self.metrics_history)
            },
            'metrics_history': [
                {
                    'timestamp': m.timestamp.isoformat(),
                    'requests_per_minute': m.requests_per_minute,
                    'success_rate': m.success_rate,
                    'memory_usage_mb': m.memory_usage_mb,
                    'cpu_usage_percent': m.cpu_usage_percent,
                    'network_latency_ms': m.network_latency_ms,
                    'consecutive_429_count': m.consecutive_429_count
                }
                for m in self.metrics_history
            ]
        }
        
        try:
            with open(filepath, 'w') as f:
                json.dump(report, f, indent=2)
            self.logger.info(f"æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜åˆ°: {filepath}")
        except Exception as e:
            self.logger.error(f"ä¿å­˜æ€§èƒ½æŠ¥å‘Šå¤±è´¥: {e}")
    
    def print_live_dashboard(self, current_metrics: PerformanceMetrics, trends: Dict, recommendations: List[str]):
        """æ‰“å°å®æ—¶ç›‘æ§é¢æ¿"""
        print("\n" + "="*80)
        print("ğŸ” PaperTracer å®æ—¶æ€§èƒ½ç›‘æ§")
        print("="*80)
        print(f"â° æ—¶é—´: {current_metrics.timestamp.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"âš¡ ä¼šè¯æ—¶é•¿: {(datetime.now() - self.start_time).total_seconds() / 60:.1f} åˆ†é’Ÿ")
        print()
        
        # æ ¸å¿ƒæŒ‡æ ‡
        print("ğŸ“Š æ ¸å¿ƒæŒ‡æ ‡:")
        print(f"   è¯·æ±‚é€Ÿç‡: {current_metrics.requests_per_minute:.1f} è¯·æ±‚/åˆ†é’Ÿ")
        print(f"   æˆåŠŸç‡: {current_metrics.success_rate:.1%}")
        print(f"   ç½‘ç»œå»¶è¿Ÿ: {current_metrics.network_latency_ms:.0f} ms" if current_metrics.network_latency_ms > 0 else "   ç½‘ç»œå»¶è¿Ÿ: æµ‹é‡å¤±è´¥")
        print(f"   429é”™è¯¯: {current_metrics.consecutive_429_count} æ¬¡è¿ç»­")
        print()
        
        # ç³»ç»Ÿèµ„æº
        print("ğŸ’» ç³»ç»Ÿèµ„æº:")
        print(f"   å†…å­˜ä½¿ç”¨: {current_metrics.memory_usage_mb:.1f} MB")
        print(f"   CPUä½¿ç”¨: {current_metrics.cpu_usage_percent:.1f}%")
        print()
        
        # è¶‹åŠ¿åˆ†æ
        if trends.get('status') == 'analyzed':
            print("ğŸ“ˆ è¶‹åŠ¿åˆ†æ:")
            rpm_trend_icon = "ğŸ“ˆ" if trends['rpm_trend'] == 'improving' else "ğŸ“‰"
            error_trend_icon = "ğŸ“‰" if trends['error_trend'] == 'improving' else "ğŸ“ˆ"
            print(f"   è¯·æ±‚é€Ÿç‡: {rpm_trend_icon} {trends['rpm_trend']} ({trends['rpm_change_percent']:+.1f}%)")
            print(f"   é”™è¯¯ç‡: {error_trend_icon} {trends['error_trend']} ({trends['error_change_percent']:+.1f}%)")
            print()
        
        # ä¼˜åŒ–å»ºè®®
        print("ğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        for i, recommendation in enumerate(recommendations[:5], 1):
            print(f"   {i}. {recommendation}")
        
        print("="*80)

def run_performance_monitor():
    """è¿è¡Œæ€§èƒ½ç›‘æ§å™¨"""
    import argparse
    
    parser = argparse.ArgumentParser(description='PaperTracer æ€§èƒ½ç›‘æ§')
    parser.add_argument('--session-dir', help='è¦ç›‘æ§çš„ä¼šè¯ç›®å½•')
    parser.add_argument('--interval', type=int, default=30, help='ç›‘æ§é—´éš”ï¼ˆç§’ï¼‰')
    parser.add_argument('--output', help='æ€§èƒ½æŠ¥å‘Šè¾“å‡ºæ–‡ä»¶')
    parser.add_argument('--quiet', action='store_true', help='é™é»˜æ¨¡å¼ï¼Œåªè¾“å‡ºè­¦å‘Š')
    
    args = parser.parse_args()
    
    monitor = PerformanceMonitor(args.session_dir)
    logger = get_logger()
    
    logger.info("ğŸ” å¯åŠ¨æ€§èƒ½ç›‘æ§å™¨...")
    logger.info(f"ç›‘æ§é—´éš”: {args.interval} ç§’")
    
    if args.session_dir:
        session_state_file = Path(args.session_dir) / "session_state.json"
        if not session_state_file.exists():
            logger.warning(f"ä¼šè¯çŠ¶æ€æ–‡ä»¶ä¸å­˜åœ¨: {session_state_file}")
    
    try:
        while True:
            # è¿™é‡Œåº”è¯¥è¿æ¥åˆ°å®é™…çš„çˆ¬è™«å®ä¾‹
            # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„çˆ¬è™«å¯¹è±¡
            class MockCrawler:
                def __init__(self):
                    self.request_count = 50
                    self.visited_urls = set(range(25))
                    self.consecutive_429_count = 2
                    self.delay_range = (3, 6)
            
            mock_crawler = MockCrawler()
            
            # æ”¶é›†æ€§èƒ½æŒ‡æ ‡
            current_metrics = monitor.create_performance_snapshot(mock_crawler)
            trends = monitor.analyze_performance_trends()
            recommendations = monitor.generate_optimization_recommendations(trends, current_metrics)
            
            # æ˜¾ç¤ºç›‘æ§é¢æ¿
            if not args.quiet:
                monitor.print_live_dashboard(current_metrics, trends, recommendations)
            else:
                # é™é»˜æ¨¡å¼ä¸‹åªæ˜¾ç¤ºè­¦å‘Š
                warnings = [r for r in recommendations if any(icon in r for icon in ['âš ï¸', 'ğŸš¨', 'âŒ'])]
                for warning in warnings:
                    logger.warning(warning)
            
            time.sleep(args.interval)
            
    except KeyboardInterrupt:
        logger.info("\nç›‘æ§å·²åœæ­¢")
        
        # ä¿å­˜æ€§èƒ½æŠ¥å‘Š
        if args.output:
            monitor.save_performance_report(args.output)
        elif args.session_dir:
            default_report = Path(args.session_dir) / f"performance_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            monitor.save_performance_report(str(default_report))

if __name__ == "__main__":
    run_performance_monitor()
